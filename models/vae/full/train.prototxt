name: "VAE"
layer {
  name: 'input-data'
  type: 'Python'
  top: 'data'
  top: 'im_info'
  top: 'labels'
  python_param {
    module: 'vae_data_layer.layer'
    layer: 'VAE_DataLayer'
    param_str: "'num_classes': 2"
  }
  include {
    phase: TRAIN
  }
}
layer {
  name: "flatdata"
  type: "Flatten"
  bottom: "data"
  top: "flatdata"
  include {
    phase: TRAIN
  }
  flatten_param {
    end_axis: 3
  }
}
layer {
  name: "encode1_"
  type: "InnerProduct"
  bottom: "data"
  top: "encode1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
	    std: 0.1
	    sparse: 15
	  }
    bias_filler {
      type: "constant"
	    value: 0
	  }
  }
  include {
    phase: TRAIN
  }
}
layer {
  name: "encode1neuron"
  type: "ReLU"
  bottom: "encode1"
  top: "encode1neuron"
  include {
    phase: TRAIN
  }
}
layer {
  name: "encode2"
  type: "InnerProduct"
  bottom: "encode1neuron"
  top: "encode2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "gaussian"
	    std: 0.1
	    sparse: 15
	  }
    bias_filler {
      type: "constant"
	    value: 0
	  }
  }
  include {
    phase: TRAIN
  }
}
layer {
  name: "encode2neuron"
  type: "ReLU"
  bottom: "encode2"
  top: "encode2neuron"
  include {
    phase: TRAIN
  }
}
layer {
  name: "encode3"
  type: "InnerProduct"
  bottom: "encode2neuron"
  top: "encode3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  inner_product_param {
    num_output: 250
    weight_filler {
      type: "gaussian"
	    std: 0.1
	    sparse: 15
	  }
    bias_filler {
      type: "constant"
	    value: 0
	  }
  }
  include {
    phase: TRAIN
  }
}
layer {
  name: "encode3neuron"
  type: "ReLU"
  bottom: "encode3"
  top: "encode3neuron"
  include {
    phase: TRAIN
  }
}


# end encoder, begin VAE z definition

layer {
  name: "mu_"
  type: "InnerProduct"
  bottom: "encode3neuron"
  top: "mu"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  inner_product_param {
    num_output: 100 # num z's
    weight_filler {
      type: "gaussian"
	    std: 0.1
	  }
    bias_filler {
      type: "constant"
	    value: 0
	  }
  }
  include {
    phase: TRAIN
  }
}
# Predict log sd because sd needs to be
# positive, and the exp ensures that it is.
layer {
  name: "logsd_"
  type: "InnerProduct"
  bottom: "encode3"
  top: "logsd"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  inner_product_param {
    num_output: 100 # num z's
    weight_filler {
      type: "gaussian"
	    std: 0.1
	  }
    bias_filler {
      type: "constant"
	    value: 0
	  }
  }
  include {
    phase: TRAIN
  }
}
layer{
  name: "sd"
  type: "Exp"
  bottom: "logsd"
  top: "sd"
  include {
    phase: TRAIN
  }
}
layer{
  name: "var"
  type: "Eltwise"
  bottom: "sd"
  bottom: "sd"
  top: "var"
  eltwise_param{
    operation: PROD
  }
  include {
    phase: TRAIN
  }
}
layer{
  name: "meansq"
  type: "Eltwise"
  bottom: "mu"
  bottom: "mu"
  top: "meansq"
  eltwise_param{
    operation: PROD
  }
  include {
    phase: TRAIN
  }
}
layer{
  name: "kldiv_plus_half"
  type: "Eltwise"
  bottom: "meansq"
  bottom: "var"
  bottom: "logsd"
  top: "kldiv_plus_half"
  eltwise_param{
    operation: SUM
    coeff: 0.5
    coeff: 0.5
    coeff: -1.0
  }
  include {
    phase: TRAIN
  }
}
layer {
  name: "kldiv"
  type: "Power"
  bottom: "kldiv_plus_half"
  top: "kldiv"
  power_param{
    shift: -0.5
  }
  include {
    phase: TRAIN
  }
}
layer{
  name: "klloss"
  type: "Reduction"
  bottom: "kldiv"
  top: "klloss"
  include {
    phase: TRAIN
  }
  #loss_weight: 0.0
  loss_weight: 0.01
  # SigmoidCrossEntropyLoss
  # normalizes by batch_size but
  # Reduction does not.
}
layer{
  name: "mu_dummy" # can't call this 'mu' or
  # caffe will try to copy
  # mu's parameters into
  # this layer at test time
  type: "DummyData"
  top: "mu"
  dummy_data_param{
    shape {
      dim: 20 # test-time batch_size
	    dim: 100 # num z's
	  }
    data_filler{
      type: "constant"
	    value: 0
	  }
  }
  include {
    phase: TEST
  }
}
layer{
  name: "sd"
  type: "DummyData"
  top: "sd"
  dummy_data_param{
    shape {
      dim: 20 # test-time batch_size
	    dim: 100 # num z's
	  }
    data_filler{
      type: "constant"
	    value: 1
	  }
  }
  include {
    phase: TEST
  }
}
layer{
  name: "noise"
  type: "DummyData"
  top: "noise"
  dummy_data_param{
    shape {
      dim: 20 # train batch_size
	    dim: 100 # num z's
	  }
    data_filler{
      type: "gaussian"
	    std: 1.
	  }
  }
  include {
    phase: TRAIN
  }
}
layer{
  name: "noise"
  type: "DummyData"
  top: "noise"
  dummy_data_param{
    shape {
      dim: 20 # test batch_size
      dim: 100 # num z's
	  }
    data_filler{
      type: "gaussian"
	    std: 1.
	  }
  }
  include {
    phase: TEST
  }
}
layer{
  name: "sdnoise"
  type: "Eltwise"
  bottom: "noise"
  bottom: "sd"
  top: "sdnoise"
  eltwise_param{
    operation: PROD
  }
}
layer{
  name: "sample"
  type: "Eltwise"
  bottom: "mu"
  bottom: "sdnoise"
  top: "sample"
  eltwise_param{
    operation: SUM
  }
}

# end VAE z's definition, begin decoder

layer {
  name: "decode4_"
  type: "InnerProduct"
  bottom: "sample"
  top: "decode4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  inner_product_param {
    num_output: 250
    weight_filler {
      type: "gaussian"
	    std: 0.1
	    sparse: 15
	  }
    bias_filler {
      type: "constant"
	    value: 0
	  }
  }
}
layer {
  name: "decode4neuron"
  type: "ReLU"
  bottom: "decode4"
  top: "decode4neuron"
}
layer {
  name: "decode3"
  type: "InnerProduct"
  bottom: "decode4neuron"
  top: "decode3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "gaussian"
	    std: 0.1
	    sparse: 15
	  }
    bias_filler {
      type: "constant"
	    value: 0
	  }
  }
}
layer {
  name: "decode3neuron"
  type: "ReLU"
  bottom: "decode3"
  top: "decode3neuron"
}
layer {
  name: "decode2"
  type: "InnerProduct"
  bottom: "decode3neuron"
  top: "decode2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
	    std: 0.1
	    sparse: 15
	  }
    bias_filler {
      type: "constant"
	    value: 0
	  }
  }
}
layer {
  name: "decode2neuron"
  type: "ReLU"
  bottom: "decode2"
  top: "decode2neuron"
}
layer {
  name: "decode1_"
  type: "InnerProduct"
  bottom: "decode2neuron"
  top: "decode1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  inner_product_param {
    num_output: 30000
    weight_filler {
      type: "gaussian"
	    std: 0.1
	    sparse: 15
	  }
    bias_filler {
      type: "constant"
	    value: 0
	  }
  }
}

layer {
  name: "loss"
  type: "EuclideanLoss"
  bottom: "decode1"
  bottom: "flatdata"
  top: "cross_entropy_loss"
  loss_weight: .1
  loss_param {
    normalization: BATCH_SIZE
  }
  include {
    phase: TRAIN
  }
}

layer {
  name: "decode1neuron"
  type: "Sigmoid"
  bottom: "decode1"
  top: "decode1neuron"
}
layer {
  name: "loss"
  type: "Silence"
  bottom: "decode1neuron"
  bottom: "flatdata"
  include {
    phase: TRAIN
  }
}
layer {
  name: "silence_info"
  type: "Silence"
  bottom: "labels"
  bottom: "im_info"
  include {
    phase: TRAIN
  }
}
layer {
  name: "kllos_brkdown"
  type: "Concat"
  #bottom: "meansq"
   bottom: "sd"
  #bottom: "logsd"
  top: "kll_brk"
  include {
    phase: TEST
  }
}

